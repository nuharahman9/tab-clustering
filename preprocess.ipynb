{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load libraries / create tokenizer object "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import string \n",
    "import numpy as np \n",
    "from nltk import word_tokenize\n",
    "from nltk.corpus import stopwords   \n",
    "from nltk.stem import PorterStemmer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from collections import Counter \n",
    "import math\n",
    "import re "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocess data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['one movi ai top head irobot one smith sinc ive seen dont rememb exact plot rememb rogu ai memor convers one robot smith mani way believ current ai technolog alreadi surpass robot movie1 matrix seri matrix take place dystopian world human trap simul made crazili advanc ai system use natur languag process talk humans2 blade blade also set dystopian futur ai call replic creat bore work howev ai becam advanc gain feel caus fight right human also use nlp commun humanswhen young read seri call higher institut villain educ hive artifici intellig becam sentient attack creator kind like termin book form childreni think movi big hero 6 relev ai one charact baymax use ai heal patient start kdrama main charact softwar engin make comput vision app let blind peopl ask question like count money front object front app tell isimit game alan ture make comput search decrypt code enigma machinei think iron man relat ai nlp iron man suit jarvi understand human languag aii think hbo silicon valley specif last season main charact work product use ai blackbox neural neti think movi resid evil movi someth ai movi red queen ai shown supercomput moviei think movi relev may someth like wall think movi relev wall develop feel similar human feel lone meet eve fall love movi show power aith artifici intellig movi robot boy awar stori famili himi cant think specif game game use speech recognit relev nlp would requir understand natur languag functionth wander earth 2 renov movi think potenti problem develop aiwestworld deu ex xfile 2001 space odysseygam son forestth termin could relev nlp termin commun human use natur languag therefor purpos commun input output termin encod spoken natur languag like english movi time someon speak ai control nlp involv issu verbal command “ run simul ” exampl one movi feel relat ai bladerunn sinc set movi heavili reli be call reploid essenti agi', 'ai control charact job assign playera robot like karen spongebob relev nlp ai human still feel thought humanbicentenni man favorit movi ai show robot develop human like trait want part human societyi think movi ex machina relev nlp ai involv creation sentient artifici intellig use languag fool human ture testin marvel charact call vision highli advanc ai act like regular human develop iron man iron man suit also built ai assist jarvi nlp ai assist abl understand human voic command execut certain action base themai common theme seen mani movi whether center around plot also time ai make appear movi item technolog featur movi use ai technolog name movi top head think marvel movi featur ai technolog iron man jarvi friday belong highperform artifici intelligenceblack mirror season 4 5 center around futur ai effect daili liveshuman race gener show center around integr ai human bodi expand save memori enhanc intellig play realist video game fulli emerg insid game sens bit dark perspect side kind show think fascin show everyon give trysom exampl game detroit becom human movi robotex machina chappiei dont watch play mani game dont know mayb iron man jarvisa movi think relev ai film ex machina movi center around ture test ai robot tri pass though ture test subject less scientif test ai pass ture test would convinc enough human impli least human level intellig game im big fan call cyanotyp daydream one main charact ai border develop human emot im interest see real role nlp could tie charact develop whether futur one dissimilar world cyanotyp daydreamth movi robot ai fight humanitymatrix replic human conscious creat artifici intellig ex machina also center around realli intellig aiin movi wander earth 2 al 550 think nlp ai contorl ai roblet battl time contol engin moon make engin engough speed leav earthther lot ai movi wall other sinc lot ai understand respond believ use nlpthe matrix cours ex machina anoth interest one larg show theme nlpi think 2 relev robot eagl eye although necessarili realist show consequ increas advanc ai iron man relev exampl ai nlp toni stark creat jarvi rather intellig system essenti person assist start kdrama main charact softwar engin make comput vision app let blind peopl ask question like count money front object front app tell isimit game alan ture make comput search decrypt codefor enigma machin', '2001 space odyssey ship ai abl sens passeng intent work themi wasnt sure discuss classmat came chappiei think iron man pretti relev nla ‘ ai focus around lot futurist tech time releas slowli becom realiti game call detroit becom human seem relev nlp ai game involv set humanoid android everyday tool human game android appear voic quit ident human game differ mani make uniform blue circl headsdeu ex machina assum ai robot use nlp process voic text order process input data formul natur speak back peopl sure readi player one show world anyon becom anyth want use technolog aiar virtual set one put headset transport univers reallif characterirobot think episod star trek also ask question advanc ai may like bicentenni man univers star war advanc ai everywher think warhamm 40k lore ai ban faction actual concept found coupl unrel seriesth movi joaquin pheonix fall love ai modelnowaday feel game alreadi use ai npc interact movi show could potenti use ai gener script dialogu exmachina free guy exampl movi relev nlp ai aspect artifici intellig understand work worldth movi one movi relev ai nlp specif agion exampl would black mirror seri netflix explor idea ai futurei think way robot abl speak relat nlpa great exampl within movi center around nlpai jarvi iron man marvel jarvi ai assist help toni stark throughout life make thing easier speech commandsmani anim movi “ ai villain ” antagonist seem almost unbeat smarter charactersth imit game movi show alan ture help crack enigma code german use send messag unsecur commun line think relev ai show tri predict like letter emerg use provid encrypt messageani movi involv robot program talk interact human relev nlp ai best exampl think hera movi think could relev big hero 6 robot think aibas robot make decis base what happen surround act accordingli thomovi show game relev nlp ai could show call person interest featur ai abl predict crime happen westworld anoth show featur use ai nlp robot creat interpret speechth movi aveng age ultron relev nlp ai ultron main villain movi creat multipl version ai self fight human avengersrobocop that think ofmovi iron mangam cyberpunk 2077 titanfall2they work ai even robotlook forward past scienc fiction relev context look present forward ai train media use nlp media relev game nier automata war human made android intellig machin anoth planet recent watch movi meg3n humanoid advanc robot feel think like human improv abil machin learn turn person creat end think movi cover aspect nlp ai ml sinc incorpor creat robot think nlp could place modifi movi script gener case specif text roleplay game instanc open world roleplay game develop prepar everi path charact might take gener new text speech fli use ai could creat immers experiencei think hbo silicon valley season 6 main product center around ai blackbox neural net']\n"
     ]
    }
   ],
   "source": [
    "ps = PorterStemmer()\n",
    "stop = set(stopwords.words('english'))\n",
    "\n",
    "def read_txt(file_path): \n",
    "    # read file contents by line \n",
    "    file = open(file_path, \"r\", encoding=\"utf-8\")\n",
    "    text = file.read() \n",
    "    text = re.sub(r'\\n', '', text)\n",
    "    text = text.translate(str.maketrans('', '', string.punctuation))\n",
    "    text = text.strip()\n",
    "    text = text.lower()\n",
    "    tokenized_words = word_tokenize(text)\n",
    "    tokenized_words = [w for w in tokenized_words if w not in stop]\n",
    "    tokenized_words = [ps.stem(word) for word in tokenized_words]\n",
    "    return ' '.join(tokenized_words)\n",
    "\n",
    "websites = [] \n",
    "websites.append(read_txt(\"movie.txt\"))\n",
    "websites.append(read_txt(\"movie2.txt\"))\n",
    "websites.append(read_txt(\"movie3.txt\"))\n",
    "print(websites)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TF / IDF Frequency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3 109\n",
      "3 114\n",
      "3 166\n",
      "3 315\n",
      "3 82\n",
      "3 41\n",
      "3 142\n",
      "3 139\n",
      "3 105\n",
      "3 44\n",
      "3 48\n",
      "3 38\n",
      "3 95\n",
      "3 25\n",
      "3 74\n",
      "3 57\n",
      "3 8\n",
      "3 93\n",
      "3 29\n",
      "3 61\n",
      "3 17\n",
      "3 13\n",
      "2 2\n",
      "3 26\n",
      "1 1\n",
      "3 3\n",
      "3 20\n",
      "2 1\n",
      "3 3\n",
      "3 2\n",
      "3 2\n",
      "2 1\n",
      "2 1\n",
      "{'o': 0.0, 'n': 0.0, 'e': 0.0, ' ': 0.0, 'm': 0.0, 'v': 0.0, 'i': 0.0, 'a': 0.0, 't': 0.0, 'p': 0.0, 'h': 0.0, 'd': 0.0, 'r': 0.0, 'b': 0.0, 's': 0.0, 'c': 0.0, 'x': 0.0, 'l': 0.0, 'g': 0.0, 'u': 0.0, 'w': 0.0, 'y': 0.0, '1': 0.8109302162163288, 'k': 0.0, 'z': 1.0986122886681098, '2': 0.0, 'f': 0.0, '6': 0.4054651081081644, 'q': 0.0, 'j': 0.0, '0': 0.0, '“': 0.4054651081081644, '”': 0.4054651081081644}\n",
      "3 196\n",
      "3 183\n",
      "3 388\n",
      "3 78\n",
      "3 135\n",
      "3 156\n",
      "3 154\n",
      "3 123\n",
      "3 108\n",
      "3 74\n",
      "3 7\n",
      "3 27\n",
      "3 89\n",
      "3 42\n",
      "3 47\n",
      "3 19\n",
      "3 208\n",
      "3 22\n",
      "3 45\n",
      "3 57\n",
      "3 95\n",
      "3 24\n",
      "3 16\n",
      "3 45\n",
      "3 11\n",
      "2 1\n",
      "1 3\n",
      "3 2\n",
      "3 1\n",
      "3 2\n",
      "{'a': 0.0, 'i': 0.0, ' ': 0.0, 'c': 0.0, 'o': 0.0, 'n': 0.0, 't': 0.0, 'r': 0.0, 'l': 0.0, 'h': 0.0, 'j': 0.0, 'b': 0.0, 's': 0.0, 'g': 0.0, 'p': 0.0, 'y': 0.0, 'e': 0.0, 'k': 0.0, 'v': 0.0, 'u': 0.0, 'm': 0.0, 'f': 0.0, 'w': 0.0, 'd': 0.0, 'x': 0.0, '4': 0.4054651081081644, '5': 3.295836866004329, '2': 0.0, '0': 0.0, 'q': 0.0}\n",
      "3 3\n",
      "3 4\n",
      "2 1\n",
      "3 466\n",
      "3 110\n",
      "3 83\n",
      "3 232\n",
      "3 97\n",
      "3 258\n",
      "3 161\n",
      "3 63\n",
      "3 18\n",
      "3 75\n",
      "3 195\n",
      "3 32\n",
      "3 127\n",
      "3 169\n",
      "3 39\n",
      "3 161\n",
      "3 31\n",
      "3 169\n",
      "3 37\n",
      "3 101\n",
      "3 75\n",
      "3 58\n",
      "1 1\n",
      "3 30\n",
      "3 3\n",
      "3 15\n",
      "2 1\n",
      "3 3\n",
      "2 1\n",
      "2 1\n",
      "2 2\n",
      "1 2\n",
      "1 1\n",
      "{'2': 0.0, '0': 0.0, '1': 0.4054651081081644, ' ': 0.0, 's': 0.0, 'p': 0.0, 'a': 0.0, 'c': 0.0, 'e': 0.0, 'o': 0.0, 'd': 0.0, 'y': 0.0, 'h': 0.0, 'i': 0.0, 'b': 0.0, 'l': 0.0, 'n': 0.0, 'g': 0.0, 't': 0.0, 'w': 0.0, 'r': 0.0, 'k': 0.0, 'm': 0.0, 'u': 0.0, 'v': 0.0, '‘': 1.0986122886681098, 'f': 0.0, 'q': 0.0, 'x': 0.0, '4': 0.4054651081081644, 'j': 0.0, '“': 0.4054651081081644, '”': 0.4054651081081644, '6': 0.8109302162163288, '7': 2.1972245773362196, '3': 1.0986122886681098}\n"
     ]
    }
   ],
   "source": [
    "doc_occurrences = {}\n",
    "def get_frequencies(website): # takes the corpus, counts its frequencies occurred in doc and stores in dictionary \n",
    "    word_freq = {} # stores the frequency of each word in a doc \n",
    "    for word in website: \n",
    "        if word in word_freq: \n",
    "            word_freq[word] += 1 \n",
    "        else: \n",
    "            word_freq[word] = 1 \n",
    "    return word_freq \n",
    "\n",
    "def get_doc_occurrences(website_dict, websites, doc_occurrences): # get the number of websites a word appears in \n",
    "    for key in website_dict: \n",
    "        if key not in doc_occurrences: \n",
    "            ct = 0 \n",
    "            for website in websites: \n",
    "                if key in website: \n",
    "                    ct = ct + 1 \n",
    "            doc_occurrences[key] = ct \n",
    "    return doc_occurrences\n",
    "\n",
    "\n",
    "def calculate_tf_idf(website, websites, n, doc_occurrences): \n",
    "    word_freqs = get_frequencies(website)\n",
    "    tf_idf = {}\n",
    "    doc_occurrences = get_doc_occurrences(word_freqs, websites, doc_occurrences)\n",
    "    tf_idf = {} \n",
    "    for key in word_freqs: \n",
    "        doc_occurs = doc_occurrences[key]\n",
    "        print(doc_occurs, word_freqs[key])\n",
    "        tf_idf[key] = word_freqs[key] * math.log(n / doc_occurs)\n",
    "    print(tf_idf)\n",
    "    return tf_idf \n",
    "\n",
    "\n",
    "for website in websites: \n",
    "    calculate_tf_idf(website, websites, len(websites), doc_occurrences=doc_occurrences)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# actual TF / IDF Frequency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         movie.txt  movie2.txt  movie3.txt\n",
      "2001      0.035696    0.000000    0.024381\n",
      "2077      0.000000    0.000000    0.032057\n",
      "40k       0.000000    0.000000    0.032057\n",
      "550       0.000000    0.037198    0.000000\n",
      "abil      0.000000    0.000000    0.032057\n",
      "...            ...         ...         ...\n",
      "world     0.027721    0.021970    0.037867\n",
      "worldth   0.000000    0.000000    0.032057\n",
      "would     0.027721    0.021970    0.018934\n",
      "xfile     0.046936    0.000000    0.000000\n",
      "young     0.046936    0.000000    0.000000\n",
      "\n",
      "[520 rows x 3 columns]\n",
      "<class 'pandas.core.frame.DataFrame'>\n"
     ]
    }
   ],
   "source": [
    "vectorizer = TfidfVectorizer(norm='l2', smooth_idf=True)\n",
    "website_content = [] \n",
    "def file_to_st(file_path): \n",
    "    file = open(file_path, \"r\", encoding=\"utf-8\")\n",
    "    text = file.read() \n",
    "    return text \n",
    "\n",
    "website_content.append(file_to_st(\"movie.txt\"))\n",
    "website_content.append(file_to_st(\"movie2.txt\"))\n",
    "website_content.append(file_to_st(\"movie3.txt\"))\n",
    "\n",
    "x = vectorizer.fit_transform(websites)\n",
    "tokens = vectorizer.get_feature_names_out()\n",
    "tfidf_df = pd.DataFrame(data = x.T.toarray(),index = tokens, columns = ['movie.txt', 'movie2.txt', 'movie3.txt'])\n",
    "print(tfidf_df)\n",
    "print(type(tfidf_df))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SVD "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(520, 3)\n",
      "(520, 3)\n",
      "w:  [[ 0.02820312  0.02614555  0.02046649]\n",
      " [ 0.01532784 -0.          0.03106882]\n",
      " [ 0.01532784 -0.          0.03106882]\n",
      " ...\n",
      " [ 0.03235515  0.00781373 -0.        ]\n",
      " [ 0.02175588  0.04807016 -0.        ]\n",
      " [ 0.02175588  0.04807016 -0.        ]] (520, 3)\n",
      "h:  [[ 0.69198507  0.71030221  0.71380236]\n",
      " [ 0.65880846 -0.         -0.        ]\n",
      " [-0.         -0.          0.55858965]] (3, 3)\n"
     ]
    }
   ],
   "source": [
    "# rank < min(m, n) for matrix m x n \n",
    "def svd_init(m, rank): \n",
    "    # convert from dataframe to array \n",
    "    arr = m.values\n",
    "    u, s, v = np.linalg.svd(arr, full_matrices=False)\n",
    "    v = v.T \n",
    "    w = np.zeros((arr.shape[0], rank)) \n",
    "    h = np.zeros((rank, arr.shape[1]))\n",
    "\n",
    "    w[:, 0] = np.sqrt(s[0]) * np.abs(u[:, 0])\n",
    "    h[0, :] = np.sqrt(s[0]) * np.abs(v[:, 0].T)\n",
    "\n",
    "    for i in range(1, rank): \n",
    "        print(u.shape)\n",
    "        x = u[:, i]\n",
    "        y = v[:, i]\n",
    "        x_p = (x >= 0) * x\n",
    "        x_n = (x < 0) * -x\n",
    "        y_p = (y >= 0) * y\n",
    "        y_n = (y <  0) * -y\n",
    "\n",
    "        xp_norm = np.linalg.norm(x_p, 2)\n",
    "        xn_norm = np.linalg.norm(x_n, 2)\n",
    "        yp_norm = np.linalg.norm(y_p, 2)\n",
    "        yn_norm = np.linalg.norm(y_n, 2)\n",
    "\n",
    "        p_norm = xp_norm * yp_norm \n",
    "        n_norm = xn_norm * yn_norm \n",
    "        if p_norm > n_norm: \n",
    "            u_i = x_p / xp_norm \n",
    "            v_i = y_p / yp_norm \n",
    "            sigma = p_norm \n",
    "        else: \n",
    "            u_i = x_n / xn_norm \n",
    "            v_i = y_n / yn_norm \n",
    "            sigma = n_norm \n",
    "        w[:, i] = np.sqrt(s[i] * sigma) * u_i\n",
    "        h[i, :] = np.sqrt(s[i] * sigma) * v_i.T \n",
    "    return w, h \n",
    "        \n",
    "    print(\"w: \", w, w.shape)\n",
    "    print(\"h: \", h, h.shape)\n",
    "\n",
    "\n",
    "w, h = svd_init(tfidf_df, 3)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NMF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.11.9 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "5c7b89af1651d0b8571dde13640ecdccf7d5a6204171d6ab33e7c296e100e08a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
